{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AngWKkqWi9Wa",
        "outputId": "b715509e-e758-430f-9c1d-f3c566fcd283"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2026.1.4)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d973f354c9d32e145c828aed00a6b1c4  haoranfei123\n"
      ],
      "metadata": {
        "id": "plwUTm-fow7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'haoranfei123'\n",
        "os.environ['KAGGLE_KEY'] = '1caa55312ab35b52fc0ea4ed285f3000'"
      ],
      "metadata": {
        "id": "JztC2qe3nvMa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c house-prices-advanced-regression-techniques\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F80PQ2yoD8N",
        "outputId": "8c6440a8-e70f-4af4-cc52-c1f1b7df30cb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading house-prices-advanced-regression-techniques.zip to /content\n",
            "\r  0% 0.00/199k [00:00<?, ?B/s]\n",
            "\r100% 199k/199k [00:00<00:00, 456MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "with zipfile.ZipFile('house-prices-advanced-regression-techniques.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df_train = pd.read_csv('train.csv')\n",
        "\n",
        "df_test = pd.read_csv('test.csv')\n",
        "\n",
        "df_sub = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "\n",
        "print(\"Train head:\")\n",
        "print(df_train.head())\n",
        "print(\"\\nTest head:\")\n",
        "print(df_test.head())\n",
        "print(\"\\nSample Submission head:\")\n",
        "print(df_sub.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNMEKVaxoOel",
        "outputId": "003d566a-52a0-4bf7-d4f5-12048ddd984f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train head:\n",
            "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
            "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
            "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
            "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
            "\n",
            "  YrSold  SaleType  SaleCondition  SalePrice  \n",
            "0   2008        WD         Normal     208500  \n",
            "1   2007        WD         Normal     181500  \n",
            "2   2008        WD         Normal     223500  \n",
            "3   2006        WD        Abnorml     140000  \n",
            "4   2008        WD         Normal     250000  \n",
            "\n",
            "[5 rows x 81 columns]\n",
            "\n",
            "Test head:\n",
            "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
            "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
            "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
            "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
            "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
            "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
            "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
            "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
            "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
            "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
            "\n",
            "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
            "0       0      6    2010        WD         Normal  \n",
            "1   12500      6    2010        WD         Normal  \n",
            "2       0      3    2010        WD         Normal  \n",
            "3       0      6    2010        WD         Normal  \n",
            "4       0      1    2010        WD         Normal  \n",
            "\n",
            "[5 rows x 80 columns]\n",
            "\n",
            "Sample Submission head:\n",
            "     Id      SalePrice\n",
            "0  1461  169277.052498\n",
            "1  1462  187758.393989\n",
            "2  1463  183583.683570\n",
            "3  1464  179317.477511\n",
            "4  1465  150730.079977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# =========================\n",
        "# 0️⃣ Prepare Data\n",
        "# =========================\n",
        "categorical_cols = df_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "df_train_encoded = pd.get_dummies(df_train, columns=categorical_cols, drop_first=True)\n",
        "df_test_encoded = pd.get_dummies(df_test, columns=categorical_cols, drop_first=True)\n",
        "df_test_encoded = df_test_encoded.reindex(columns=df_train_encoded.columns.drop('SalePrice'), fill_value=0)\n",
        "\n",
        "# Fill missing numerical values with median\n",
        "num_cols = df_train_encoded.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "num_cols.remove('SalePrice')\n",
        "for col in num_cols:\n",
        "    median = df_train_encoded[col].median()\n",
        "    df_train_encoded[col] = df_train_encoded[col].fillna(median)\n",
        "    df_test_encoded[col] = df_test_encoded[col].fillna(median)\n",
        "\n",
        "# Features & target\n",
        "X = df_train_encoded.drop('SalePrice', axis=1)\n",
        "y = np.log1p(df_train_encoded['SalePrice'])  # log-transform target\n",
        "X_test = df_test_encoded\n",
        "\n",
        "# =========================\n",
        "# 1️⃣ Standardize Features\n",
        "# =========================\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train-validation split for metrics\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# =========================\n",
        "# 2️⃣ Linear Regression\n",
        "# =========================\n",
        "lin_reg = LinearRegression()\n",
        "# 5-fold CV RMSE\n",
        "lin_cv_scores = cross_val_score(lin_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "lin_rmse_scores = np.sqrt(-lin_cv_scores)\n",
        "print(\"Linear Regression CV RMSE:\", lin_rmse_scores)\n",
        "print(\"Linear Regression CV RMSE mean:\", lin_rmse_scores.mean())\n",
        "\n",
        "# Fit and Validation R2\n",
        "lin_reg.fit(X_train, y_train)\n",
        "y_val_pred_lin = lin_reg.predict(X_val)\n",
        "print(\"Linear Regression Validation R2:\", r2_score(y_val, y_val_pred_lin))\n",
        "\n",
        "# =========================\n",
        "# 3️⃣ Ridge Regression\n",
        "# =========================\n",
        "alphas = [0.1, 0.3, 1, 3, 10, 30, 100]\n",
        "ridge_cv = RidgeCV(alphas=alphas, scoring='neg_mean_squared_error', cv=5)\n",
        "ridge_cv.fit(X_train, y_train)\n",
        "y_val_pred_ridge = ridge_cv.predict(X_val)\n",
        "\n",
        "print(\"Best alpha for Ridge:\", ridge_cv.alpha_)\n",
        "\n",
        "ridge_cv_scores = cross_val_score(ridge_cv, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "ridge_rmse_scores = np.sqrt(-ridge_cv_scores)\n",
        "print(\"Ridge CV RMSE scores:\", ridge_rmse_scores)\n",
        "print(\"Ridge CV RMSE mean:\", ridge_rmse_scores.mean())\n",
        "print(\"Ridge Validation R2:\", r2_score(y_val, y_val_pred_ridge))\n",
        "\n",
        "# Sequential alpha experiments\n",
        "for alpha in [0.1, 1, 10, 100, 1000]:\n",
        "    ridge = RidgeCV(alphas=[alpha], scoring='neg_mean_squared_error', cv=5)\n",
        "    ridge.fit(X_train, y_train)\n",
        "    y_val_pred_alpha = ridge.predict(X_val)\n",
        "    rmse = np.sqrt(mean_squared_error(np.expm1(y_val), np.expm1(y_val_pred_alpha)))\n",
        "    print(f\"Ridge alpha={alpha}, Validation RMSE: {rmse:.2f}\")\n",
        "\n",
        "# =========================\n",
        "# 4️⃣ Visualization\n",
        "# =========================\n",
        "# Top 20 Feature Correlation Heatmap\n",
        "corr_matrix = df_train_encoded.corr()\n",
        "top_features = corr_matrix['SalePrice'].abs().sort_values(ascending=False).head(20).index\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(df_train_encoded[top_features].corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.title(\"Top 20 Feature Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# Linear & Ridge top 20 coefficients\n",
        "lin_coeffs = pd.Series(lin_reg.coef_, index=X.columns)\n",
        "top_lin_coeffs = lin_coeffs.abs().sort_values(ascending=False).head(20)\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=top_lin_coeffs.values, y=top_lin_coeffs.index)\n",
        "plt.title(\"Top 20 Linear Regression Feature Coefficients\")\n",
        "plt.xlabel(\"Coefficient Magnitude\")\n",
        "plt.show()\n",
        "\n",
        "ridge_coeffs = pd.Series(ridge_cv.coef_, index=X.columns)\n",
        "top_ridge_coeffs = ridge_coeffs.abs().sort_values(ascending=False).head(20)\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=top_ridge_coeffs.values, y=top_ridge_coeffs.index)\n",
        "plt.title(\"Top 20 Ridge Regression Feature Coefficients\")\n",
        "plt.xlabel(\"Coefficient Magnitude\")\n",
        "plt.show()\n",
        "\n",
        "# Scatter plots\n",
        "y_train_exp = np.expm1(y_train)\n",
        "y_train_pred_exp_lin = np.expm1(lin_reg.predict(X_train))\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=y_train_exp, y=y_train_pred_exp_lin, alpha=0.6)\n",
        "plt.plot([y_train_exp.min(), y_train_exp.max()], [y_train_exp.min(), y_train_exp.max()],\n",
        "         color='red', linestyle='--', lw=2)\n",
        "plt.xscale('log'); plt.yscale('log')\n",
        "plt.xlabel(\"True SalePrice\"); plt.ylabel(\"Predicted SalePrice (Linear)\")\n",
        "plt.title(\"Training Set: Linear Regression\")\n",
        "plt.show()\n",
        "\n",
        "y_train_pred_exp_ridge = np.expm1(ridge_cv.predict(X_train))\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=y_train_exp, y=y_train_pred_exp_ridge, alpha=0.6)\n",
        "plt.plot([y_train_exp.min(), y_train_exp.max()], [y_train_exp.min(), y_train_exp.max()],\n",
        "         color='red', linestyle='--', lw=2)\n",
        "plt.xscale('log'); plt.yscale('log')\n",
        "plt.xlabel(\"True SalePrice\"); plt.ylabel(\"Predicted SalePrice (Ridge)\")\n",
        "plt.title(f\"Training Set: Ridge Regression (alpha={ridge_cv.alpha_})\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3TQcXqFNOPVi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}